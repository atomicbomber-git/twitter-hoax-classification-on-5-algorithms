{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-1 pada algoritma *Naive Bayes*, jumlah *true negative* (tn) = 3, *false positive* (fp) = 9, *false negative* (fn) = 0; Dan *true positive* (tp) = 48. Maka nilai *precision* = tp / (tp + fp) =  48 / (48 + 48) = 0.8421; Nilai *recall* = tp / (tp + fn) = 48 / (48 + 0) = 1.0000; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.8421 ✕ 1.0000 / (0.8421 + 1.0000) = 0.9143$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 48 + 3 / (48 + 9 + 3 + 0) = 0.8500.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-1 pada algoritma *Support Vector Machine*, jumlah *true negative* (tn) = 2, *false positive* (fp) = 10, *false negative* (fn) = 0; Dan *true positive* (tp) = 48. Maka nilai *precision* = tp / (tp + fp) =  48 / (48 + 48) = 0.8276; Nilai *recall* = tp / (tp + fn) = 48 / (48 + 0) = 1.0000; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.8276 ✕ 1.0000 / (0.8276 + 1.0000) = 0.9057$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 48 + 2 / (48 + 10 + 2 + 0) = 0.8333.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-1 pada algoritma *Multilayer Perceptron*, jumlah *true negative* (tn) = 9, *false positive* (fp) = 3, *false negative* (fn) = 8; Dan *true positive* (tp) = 40. Maka nilai *precision* = tp / (tp + fp) =  40 / (40 + 40) = 0.9302; Nilai *recall* = tp / (tp + fn) = 40 / (40 + 8) = 0.8333; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.9302 ✕ 0.8333 / (0.9302 + 0.8333) = 0.8791$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 40 + 9 / (40 + 3 + 9 + 8) = 0.8167.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-1 pada algoritma *Decision Tree*, jumlah *true negative* (tn) = 8, *false positive* (fp) = 4, *false negative* (fn) = 14; Dan *true positive* (tp) = 34. Maka nilai *precision* = tp / (tp + fp) =  34 / (34 + 34) = 0.8947; Nilai *recall* = tp / (tp + fn) = 34 / (34 + 14) = 0.7083; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.8947 ✕ 0.7083 / (0.8947 + 0.7083) = 0.7907$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 34 + 8 / (34 + 4 + 8 + 14) = 0.7000.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-1 pada algoritma *Random Forest*, jumlah *true negative* (tn) = 5, *false positive* (fp) = 7, *false negative* (fn) = 4; Dan *true positive* (tp) = 44. Maka nilai *precision* = tp / (tp + fp) =  44 / (44 + 44) = 0.8627; Nilai *recall* = tp / (tp + fn) = 44 / (44 + 4) = 0.9167; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.8627 ✕ 0.9167 / (0.8627 + 0.9167) = 0.8889$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 44 + 5 / (44 + 7 + 5 + 4) = 0.8167.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-2 pada algoritma *Naive Bayes*, jumlah *true negative* (tn) = 0, *false positive* (fp) = 1, *false negative* (fn) = 0; Dan *true positive* (tp) = 59. Maka nilai *precision* = tp / (tp + fp) =  59 / (59 + 59) = 0.9833; Nilai *recall* = tp / (tp + fn) = 59 / (59 + 0) = 1.0000; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.9833 ✕ 1.0000 / (0.9833 + 1.0000) = 0.9916$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 59 + 0 / (59 + 1 + 0 + 0) = 0.9833.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-2 pada algoritma *Support Vector Machine*, jumlah *true negative* (tn) = 0, *false positive* (fp) = 1, *false negative* (fn) = 0; Dan *true positive* (tp) = 59. Maka nilai *precision* = tp / (tp + fp) =  59 / (59 + 59) = 0.9833; Nilai *recall* = tp / (tp + fn) = 59 / (59 + 0) = 1.0000; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.9833 ✕ 1.0000 / (0.9833 + 1.0000) = 0.9916$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 59 + 0 / (59 + 1 + 0 + 0) = 0.9833.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-2 pada algoritma *Multilayer Perceptron*, jumlah *true negative* (tn) = 1, *false positive* (fp) = 0, *false negative* (fn) = 21; Dan *true positive* (tp) = 38. Maka nilai *precision* = tp / (tp + fp) =  38 / (38 + 38) = 1.0000; Nilai *recall* = tp / (tp + fn) = 38 / (38 + 21) = 0.6441; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 1.0000 ✕ 0.6441 / (1.0000 + 0.6441) = 0.7835$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 38 + 1 / (38 + 0 + 1 + 21) = 0.6500.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-2 pada algoritma *Decision Tree*, jumlah *true negative* (tn) = 0, *false positive* (fp) = 1, *false negative* (fn) = 8; Dan *true positive* (tp) = 51. Maka nilai *precision* = tp / (tp + fp) =  51 / (51 + 51) = 0.9808; Nilai *recall* = tp / (tp + fn) = 51 / (51 + 8) = 0.8644; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.9808 ✕ 0.8644 / (0.9808 + 0.8644) = 0.9189$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 51 + 0 / (51 + 1 + 0 + 8) = 0.8500.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-2 pada algoritma *Random Forest*, jumlah *true negative* (tn) = 0, *false positive* (fp) = 1, *false negative* (fn) = 6; Dan *true positive* (tp) = 53. Maka nilai *precision* = tp / (tp + fp) =  53 / (53 + 53) = 0.9815; Nilai *recall* = tp / (tp + fn) = 53 / (53 + 6) = 0.8983; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.9815 ✕ 0.8983 / (0.9815 + 0.8983) = 0.9381$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 53 + 0 / (53 + 1 + 0 + 6) = 0.8833.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-3 pada algoritma *Naive Bayes*, jumlah *true negative* (tn) = 0, *false positive* (fp) = 9, *false negative* (fn) = 0; Dan *true positive* (tp) = 51. Maka nilai *precision* = tp / (tp + fp) =  51 / (51 + 51) = 0.8500; Nilai *recall* = tp / (tp + fn) = 51 / (51 + 0) = 1.0000; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.8500 ✕ 1.0000 / (0.8500 + 1.0000) = 0.9189$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 51 + 0 / (51 + 9 + 0 + 0) = 0.8500.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-3 pada algoritma *Support Vector Machine*, jumlah *true negative* (tn) = 0, *false positive* (fp) = 9, *false negative* (fn) = 0; Dan *true positive* (tp) = 51. Maka nilai *precision* = tp / (tp + fp) =  51 / (51 + 51) = 0.8500; Nilai *recall* = tp / (tp + fn) = 51 / (51 + 0) = 1.0000; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.8500 ✕ 1.0000 / (0.8500 + 1.0000) = 0.9189$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 51 + 0 / (51 + 9 + 0 + 0) = 0.8500.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-3 pada algoritma *Multilayer Perceptron*, jumlah *true negative* (tn) = 0, *false positive* (fp) = 9, *false negative* (fn) = 6; Dan *true positive* (tp) = 45. Maka nilai *precision* = tp / (tp + fp) =  45 / (45 + 45) = 0.8333; Nilai *recall* = tp / (tp + fn) = 45 / (45 + 6) = 0.8824; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.8333 ✕ 0.8824 / (0.8333 + 0.8824) = 0.8571$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 45 + 0 / (45 + 9 + 0 + 6) = 0.7500.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-3 pada algoritma *Decision Tree*, jumlah *true negative* (tn) = 3, *false positive* (fp) = 6, *false negative* (fn) = 11; Dan *true positive* (tp) = 40. Maka nilai *precision* = tp / (tp + fp) =  40 / (40 + 40) = 0.8696; Nilai *recall* = tp / (tp + fn) = 40 / (40 + 11) = 0.7843; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.8696 ✕ 0.7843 / (0.8696 + 0.7843) = 0.8247$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 40 + 3 / (40 + 6 + 3 + 11) = 0.7167.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-3 pada algoritma *Random Forest*, jumlah *true negative* (tn) = 4, *false positive* (fp) = 5, *false negative* (fn) = 5; Dan *true positive* (tp) = 46. Maka nilai *precision* = tp / (tp + fp) =  46 / (46 + 46) = 0.9020; Nilai *recall* = tp / (tp + fn) = 46 / (46 + 5) = 0.9020; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.9020 ✕ 0.9020 / (0.9020 + 0.9020) = 0.9020$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 46 + 4 / (46 + 5 + 4 + 5) = 0.8333.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-4 pada algoritma *Naive Bayes*, jumlah *true negative* (tn) = 2, *false positive* (fp) = 23, *false negative* (fn) = 0; Dan *true positive* (tp) = 35. Maka nilai *precision* = tp / (tp + fp) =  35 / (35 + 35) = 0.6034; Nilai *recall* = tp / (tp + fn) = 35 / (35 + 0) = 1.0000; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.6034 ✕ 1.0000 / (0.6034 + 1.0000) = 0.7527$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 35 + 2 / (35 + 23 + 2 + 0) = 0.6167.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-4 pada algoritma *Support Vector Machine*, jumlah *true negative* (tn) = 2, *false positive* (fp) = 23, *false negative* (fn) = 0; Dan *true positive* (tp) = 35. Maka nilai *precision* = tp / (tp + fp) =  35 / (35 + 35) = 0.6034; Nilai *recall* = tp / (tp + fn) = 35 / (35 + 0) = 1.0000; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.6034 ✕ 1.0000 / (0.6034 + 1.0000) = 0.7527$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 35 + 2 / (35 + 23 + 2 + 0) = 0.6167.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-4 pada algoritma *Multilayer Perceptron*, jumlah *true negative* (tn) = 6, *false positive* (fp) = 19, *false negative* (fn) = 1; Dan *true positive* (tp) = 34. Maka nilai *precision* = tp / (tp + fp) =  34 / (34 + 34) = 0.6415; Nilai *recall* = tp / (tp + fn) = 34 / (34 + 1) = 0.9714; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.6415 ✕ 0.9714 / (0.6415 + 0.9714) = 0.7727$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 34 + 6 / (34 + 19 + 6 + 1) = 0.6667.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-4 pada algoritma *Decision Tree*, jumlah *true negative* (tn) = 8, *false positive* (fp) = 17, *false negative* (fn) = 3; Dan *true positive* (tp) = 32. Maka nilai *precision* = tp / (tp + fp) =  32 / (32 + 32) = 0.6531; Nilai *recall* = tp / (tp + fn) = 32 / (32 + 3) = 0.9143; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.6531 ✕ 0.9143 / (0.6531 + 0.9143) = 0.7619$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 32 + 8 / (32 + 17 + 8 + 3) = 0.6667.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-4 pada algoritma *Random Forest*, jumlah *true negative* (tn) = 4, *false positive* (fp) = 21, *false negative* (fn) = 3; Dan *true positive* (tp) = 32. Maka nilai *precision* = tp / (tp + fp) =  32 / (32 + 32) = 0.6038; Nilai *recall* = tp / (tp + fn) = 32 / (32 + 3) = 0.9143; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.6038 ✕ 0.9143 / (0.6038 + 0.9143) = 0.7273$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 32 + 4 / (32 + 21 + 4 + 3) = 0.6000.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-5 pada algoritma *Naive Bayes*, jumlah *true negative* (tn) = 1, *false positive* (fp) = 19, *false negative* (fn) = 0; Dan *true positive* (tp) = 40. Maka nilai *precision* = tp / (tp + fp) =  40 / (40 + 40) = 0.6780; Nilai *recall* = tp / (tp + fn) = 40 / (40 + 0) = 1.0000; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.6780 ✕ 1.0000 / (0.6780 + 1.0000) = 0.8081$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 40 + 1 / (40 + 19 + 1 + 0) = 0.6833.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-5 pada algoritma *Support Vector Machine*, jumlah *true negative* (tn) = 1, *false positive* (fp) = 19, *false negative* (fn) = 0; Dan *true positive* (tp) = 40. Maka nilai *precision* = tp / (tp + fp) =  40 / (40 + 40) = 0.6780; Nilai *recall* = tp / (tp + fn) = 40 / (40 + 0) = 1.0000; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.6780 ✕ 1.0000 / (0.6780 + 1.0000) = 0.8081$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 40 + 1 / (40 + 19 + 1 + 0) = 0.6833.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-5 pada algoritma *Multilayer Perceptron*, jumlah *true negative* (tn) = 2, *false positive* (fp) = 18, *false negative* (fn) = 3; Dan *true positive* (tp) = 37. Maka nilai *precision* = tp / (tp + fp) =  37 / (37 + 37) = 0.6727; Nilai *recall* = tp / (tp + fn) = 37 / (37 + 3) = 0.9250; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.6727 ✕ 0.9250 / (0.6727 + 0.9250) = 0.7789$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 37 + 2 / (37 + 18 + 2 + 3) = 0.6500.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-5 pada algoritma *Decision Tree*, jumlah *true negative* (tn) = 6, *false positive* (fp) = 14, *false negative* (fn) = 6; Dan *true positive* (tp) = 34. Maka nilai *precision* = tp / (tp + fp) =  34 / (34 + 34) = 0.7083; Nilai *recall* = tp / (tp + fn) = 34 / (34 + 6) = 0.8500; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.7083 ✕ 0.8500 / (0.7083 + 0.8500) = 0.7727$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 34 + 6 / (34 + 14 + 6 + 6) = 0.6667.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\nPada diagram dibawah, dapat dilihat bahwa untuk fold ke-5 pada algoritma *Random Forest*, jumlah *true negative* (tn) = 2, *false positive* (fp) = 18, *false negative* (fn) = 4; Dan *true positive* (tp) = 36. Maka nilai *precision* = tp / (tp + fp) =  36 / (36 + 36) = 0.6667; Nilai *recall* = tp / (tp + fn) = 36 / (36 + 4) = 0.9000; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ 0.6667 ✕ 0.9000 / (0.6667 + 0.9000) = 0.7660$; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = 36 + 2 / (36 + 18 + 2 + 4) = 0.6333.\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "from functools import reduce\n",
    "from sklearn.metrics import (\n",
    "    plot_confusion_matrix,\n",
    "    precision_recall_fscore_support,\n",
    "    plot_roc_curve,\n",
    "    accuracy_score,\n",
    "    plot_precision_recall_curve,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "from constants import *\n",
    "from train import get_model_file_name, get_test_file_name, get_vectorizer_file_name\n",
    "\n",
    "report_calculation_file = open(\"./report-extras/report-calculation.txt\", \"w\")\n",
    "\n",
    "\n",
    "def get_test_result_file_name(fold):\n",
    "    return \"./test_result_data/hasil_uji_{}.csv\".format(fold)\n",
    "\n",
    "\n",
    "ALGORITHMS = [\n",
    "    NAIVE_BAYES_ID,\n",
    "    SVM_ID,\n",
    "    MULTILAYER_PERCEPTRON_ID,\n",
    "    DECISION_TREE_ID,\n",
    "    RANDOM_FOREST_ID,\n",
    "]\n",
    "\n",
    "test_results_per_algorithm = {\n",
    "    NAIVE_BAYES_ID: [],\n",
    "    SVM_ID: [],\n",
    "    MULTILAYER_PERCEPTRON_ID: [],\n",
    "    DECISION_TREE_ID: [],\n",
    "    RANDOM_FOREST_ID: [],\n",
    "}\n",
    "\n",
    "plot_list = {\n",
    "    NAIVE_BAYES_ID: {},\n",
    "    SVM_ID: {},\n",
    "    MULTILAYER_PERCEPTRON_ID: {},\n",
    "    DECISION_TREE_ID: {},\n",
    "    RANDOM_FOREST_ID: {},\n",
    "}\n",
    "\n",
    "for key in plot_list:\n",
    "    roc_fig, roc_ax = plt.subplots()\n",
    "    plot_list[key][\"roc_ax\"] = roc_ax\n",
    "    plot_list[key][\"roc_fig\"] = roc_fig\n",
    "\n",
    "    prc_fig, prc_ax = plt.subplots()\n",
    "    plot_list[key][\"prc_ax\"] = prc_ax\n",
    "    plot_list[key][\"prc_fig\"] = prc_fig\n",
    "\n",
    "for fold in range(0, N_FOLDS):\n",
    "    test_results_per_fold = []\n",
    "\n",
    "    for algorithm_id in ALGORITHMS:\n",
    "        model = joblib.load(get_model_file_name(algorithm_id, fold))\n",
    "\n",
    "        test_file = pandas.read_csv(get_test_file_name(fold))\n",
    "        data_test = test_file[DATA_KEY]\n",
    "        target_test = test_file[TARGET_KEY]\n",
    "\n",
    "        tfidf_vectorizer = joblib.load(get_vectorizer_file_name(fold))\n",
    "\n",
    "        processed_data_test = tfidf_vectorizer.transform(data_test).toarray()\n",
    "\n",
    "        predicted_data_test = model.predict(processed_data_test)\n",
    "\n",
    "        # Plot and save confusion matrix\n",
    "        plot_confusion_matrix(\n",
    "            model,\n",
    "            processed_data_test,\n",
    "            target_test,\n",
    "            labels=[\"f\", \"h\"],\n",
    "            display_labels=[\"Fakta\", \"Hoax\"],\n",
    "            cmap=\"Greys\",\n",
    "        )\n",
    "\n",
    "        plt.ylabel(\"Kelas Prediksi\")\n",
    "        plt.xlabel(\"Hasil Prediksi\")\n",
    "\n",
    "        plt.savefig(\n",
    "            \"./images/{}_{}_CONFUSION_MATRIX.png\".format(\n",
    "                fold,\n",
    "                algorithm_id,\n",
    "            )\n",
    "        )\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "\n",
    "        # Plot and save ROC Curve\n",
    "        name = \"{}{}\".format(ALGORITHM_SHORT_LABELS[algorithm_id], fold + 1)\n",
    "\n",
    "        plot_roc_curve(\n",
    "            model,\n",
    "            processed_data_test,\n",
    "            target_test,\n",
    "            name=name,\n",
    "            ax=plot_list[algorithm_id][\"roc_ax\"],\n",
    "        )\n",
    "\n",
    "        plot_precision_recall_curve(\n",
    "            model,\n",
    "            processed_data_test,\n",
    "            target_test,\n",
    "            name=name,\n",
    "            ax=plot_list[algorithm_id][\"prc_ax\"],\n",
    "        )\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(\n",
    "            target_test,\n",
    "            predicted_data_test,\n",
    "        ).ravel()\n",
    "\n",
    "\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1_score = 2 * precision * recall / (precision + recall)\n",
    "        accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "        display(\n",
    "            Markdown(\n",
    "                f\"\"\"\n",
    "Pada diagram di bawah, dapat dilihat bahwa untuk fold ke-{fold + 1} pada algoritma *{ALGORITHM_LABELS[algorithm_id]}*, jumlah *true negative* (tn) = {tn}, *false positive* (fp) = {fp}, *false negative* (fn) = {fn}; Dan *true positive* (tp) = {tp}. Maka nilai *precision* = tp / (tp + fp) =  {tp} / ({tp} + {tp}) = {precision:0.4f}; Nilai *recall* = tp / (tp + fn) = {tp} / ({tp} + {fn}) = {recall:0.4f}; *F1-Score* = 2 ✕ *precision* ✕ *recall* / (*precision* + *recall*) = 2 ✕ {precision:0.4f} ✕ {recall:0.4f} / ({precision:0.4f} + {recall:0.4f}) = {f1_score:0.4f}; Nilai *accuracy* = tp + tn / (tp + fp + tn + fn) = {tp} + {tn} / ({tp} + {fp} + {tn} + {fn}) = {accuracy:0.4f}.\n",
    "\"\"\"         )\n",
    "        )\n",
    "\n",
    "\n",
    "        print(\n",
    "            \"\"\"Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-{} pada algoritma {}, jumlah true negative (tn) = {:.2f}, false positive (fp) = {:.2f}, false negative (fn) = {:.2f}; Dan true positive (tp) = {:.2f}. Maka nilai precision = tp / (tp + fp) =  {:.2f} / ({:.2f} + {:.2f})= {:.2f}; Nilai recall = tp / (tp + fn) = {:.2f} / ({:.2f} + {:.2f}) = {:.2f}; F1-score = 2 x precision x recall / (precision + recall) = 2 x {:.2f} x {:.2f} / ({:.2f} + {:.2f}) = {:.2f}; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = {:.2f} + {:.2f} / ({:.2f} + {:.2f} + {:.2f} + {:.2f}) = {:.2f}.\\n\n",
    "            \"\"\".format(\n",
    "                fold + 1, \n",
    "                ALGORITHM_LABELS[algorithm_id],\n",
    "                tn, fp, fn, tp,\n",
    "                tp, tp, fp, precision,\n",
    "                tp, tp, fn, recall,\n",
    "                precision, recall, precision, recall, f1_score,\n",
    "                tp, tn, tp, fp, tn, fn, accuracy,\n",
    "            ).strip(\n",
    "            ),\n",
    "            file=report_calculation_file\n",
    "        )\n",
    "        \n",
    "        precision, recall, f_score, support = precision_recall_fscore_support(\n",
    "            target_test,\n",
    "            predicted_data_test,\n",
    "            pos_label=\"h\",\n",
    "            zero_division=0,\n",
    "            average=\"binary\",\n",
    "        )\n",
    "\n",
    "        accuracy = accuracy_score(target_test, predicted_data_test)\n",
    "\n",
    "        test_results_per_algorithm[algorithm_id].append(\n",
    "            {\n",
    "                \"Precision\": precision,\n",
    "                \"Recall\": recall,\n",
    "                \"F1-Score\": f_score,\n",
    "                \"Accuracy\": accuracy,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        test_results_per_fold.append(\n",
    "            {\n",
    "                \"Algoritma\": ALGORITHM_LABELS[algorithm_id],\n",
    "                \"Precision\": precision,\n",
    "                \"Recall\": recall,\n",
    "                \"F1-Score\": f_score,\n",
    "                \"Accuracy\": accuracy,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        \"Berikut merupakan tabel hasil pengujian untuk fold {}.\\n\".format(\n",
    "            fold + 1\n",
    "        ),\n",
    "        file=report_calculation_file\n",
    "    )\n",
    "\n",
    "    pandas.DataFrame(\n",
    "        test_results_per_fold,\n",
    "    ).to_csv(\n",
    "        get_test_result_file_name(fold + 1),\n",
    "        float_format=\"%0.4f\",\n",
    "    )\n",
    "\n",
    "for algorithm_id in plot_list:\n",
    "    roc_fig = plot_list[algorithm_id][\"roc_fig\"]\n",
    "    roc_fig.savefig(\"./images/ROC_CURVE_{}.png\".format(algorithm_id))\n",
    "    roc_fig.clf()\n",
    "\n",
    "    prc_fig = plot_list[algorithm_id][\"prc_fig\"]\n",
    "    prc_fig.savefig(\"./images/PPC_CURVE_{}.png\".format(algorithm_id))\n",
    "    prc_fig.clf()\n",
    "\n",
    "averages_list = []\n",
    "\n",
    "for algorithm_id, test_result in test_results_per_algorithm.items():\n",
    "    averages_list.append({\n",
    "        \"Algoritma\": ALGORITHM_LABELS[algorithm_id],\n",
    "        **pandas.DataFrame(test_result).mean().to_dict()\n",
    "    })\n",
    "\n",
    "report_average_df = pandas.DataFrame(\n",
    "    averages_list\n",
    ")\n",
    "report_average_df.set_index(\n",
    "    \"Algoritma\",\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "report_average_df.agg({\n",
    "    'Precision': ['min', 'max'],\n",
    "    'Recall': ['min', 'max'],\n",
    "    'F1-Score': ['min', 'max'],\n",
    "    'Accuracy': ['min', 'max'],\n",
    "})\n",
    "\n",
    "report_average_df.to_csv(\n",
    "    \"./test_result_data/Rata-Rata Hasil Penelitian.csv\",\n",
    "    float_format=\"%0.4f\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x4b68718>"
      ],
      "text/html": "<style  type=\"text/css\" >\n#T_c577e033_0881_11eb_8810_309c23d45c3drow0_col1,#T_c577e033_0881_11eb_8810_309c23d45c3drow0_col2,#T_c577e033_0881_11eb_8810_309c23d45c3drow0_col3,#T_c577e033_0881_11eb_8810_309c23d45c3drow1_col1,#T_c577e033_0881_11eb_8810_309c23d45c3drow3_col0{\n            background-color:  green;\n             color:  white;\n        }#T_c577e033_0881_11eb_8810_309c23d45c3drow1_col0,#T_c577e033_0881_11eb_8810_309c23d45c3drow2_col3,#T_c577e033_0881_11eb_8810_309c23d45c3drow3_col1,#T_c577e033_0881_11eb_8810_309c23d45c3drow3_col2{\n            background-color:  red;\n        }</style><table id=\"T_c577e033_0881_11eb_8810_309c23d45c3d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Precision</th>        <th class=\"col_heading level0 col1\" >Recall</th>        <th class=\"col_heading level0 col2\" >F1-Score</th>        <th class=\"col_heading level0 col3\" >Accuracy</th>    </tr>    <tr>        <th class=\"index_name level0\" >Algoritma</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_c577e033_0881_11eb_8810_309c23d45c3dlevel0_row0\" class=\"row_heading level0 row0\" >Naive Bayes</th>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow0_col0\" class=\"data row0 col0\" >0.7914</td>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow0_col1\" class=\"data row0 col1\" >1.0000</td>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow0_col2\" class=\"data row0 col2\" >0.8771</td>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow0_col3\" class=\"data row0 col3\" >0.7967</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c577e033_0881_11eb_8810_309c23d45c3dlevel0_row1\" class=\"row_heading level0 row1\" >Support Vector Machine</th>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow1_col0\" class=\"data row1 col0\" >0.7885</td>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow1_col1\" class=\"data row1 col1\" >1.0000</td>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow1_col2\" class=\"data row1 col2\" >0.8754</td>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow1_col3\" class=\"data row1 col3\" >0.7933</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c577e033_0881_11eb_8810_309c23d45c3dlevel0_row2\" class=\"row_heading level0 row2\" >Multilayer Perceptron</th>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow2_col0\" class=\"data row2 col0\" >0.8156</td>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow2_col1\" class=\"data row2 col1\" >0.8512</td>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow2_col2\" class=\"data row2 col2\" >0.8143</td>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow2_col3\" class=\"data row2 col3\" >0.7067</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c577e033_0881_11eb_8810_309c23d45c3dlevel0_row3\" class=\"row_heading level0 row3\" >Decision Tree</th>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow3_col0\" class=\"data row3 col0\" >0.8213</td>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow3_col1\" class=\"data row3 col1\" >0.8243</td>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow3_col2\" class=\"data row3 col2\" >0.8138</td>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow3_col3\" class=\"data row3 col3\" >0.7200</td>\n            </tr>\n            <tr>\n                        <th id=\"T_c577e033_0881_11eb_8810_309c23d45c3dlevel0_row4\" class=\"row_heading level0 row4\" >Random Forest</th>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow4_col0\" class=\"data row4 col0\" >0.8033</td>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow4_col1\" class=\"data row4 col1\" >0.9062</td>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow4_col2\" class=\"data row4 col2\" >0.8444</td>\n                        <td id=\"T_c577e033_0881_11eb_8810_309c23d45c3drow4_col3\" class=\"data row4 col3\" >0.7533</td>\n            </tr>\n    </tbody></table>"
     },
     "metadata": {},
     "execution_count": 251
    }
   ],
   "source": [
    "def highlight(s):\n",
    "    is_max = s == s.max()\n",
    "    is_min = s == s.min()\n",
    "    \n",
    "    return ['background-color: green; color: white;' if v == s.max() else 'background-color: red' if v == s.min() else '' for v in s]    \n",
    "\n",
    "report_average_df.style.apply(\n",
    "    highlight\n",
    ").format(\n",
    "    \"{:0.4f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_with_and(target_list, conjunction=\"dan\"):\n",
    "    target_list = [f\"*{word}*\" for word in target_list]\n",
    "\n",
    "    if (len(target_list) == 0):\n",
    "        return \"\"\n",
    "    elif (len(target_list) == 1):\n",
    "        return target_list[0]\n",
    "    elif (len(target_list) == 2):\n",
    "        return f\"{target_list[0]} {conjunction} {target_list[1]}\"\n",
    "    else:\n",
    "        return \", \".join(target_list[:-1]) + f\", {conjunction} \"  + target_list[-1]\n",
    "\n",
    "def better_idxmin(data_frame):\n",
    "    return data_frame.idxmin().reset_index().apply(\n",
    "        lambda row: [\n",
    "            row[\"index\"],\n",
    "            data_frame[\n",
    "                data_frame[row[\"index\"]] == data_frame.min()[row[\"index\"]]\n",
    "            ].index.to_list(),\n",
    "        ],\n",
    "        axis=1,\n",
    "        result_type=\"expand\",\n",
    "    ).set_index(0).T.iloc[0]\n",
    "\n",
    "def better_idxmax(data_frame):\n",
    "    return data_frame.idxmax().reset_index().apply(\n",
    "        lambda row: [\n",
    "            row[\"index\"],\n",
    "            data_frame[\n",
    "                data_frame[row[\"index\"]] == data_frame.max()[row[\"index\"]]\n",
    "            ].index.to_list(),\n",
    "        ],\n",
    "        axis=1,\n",
    "        result_type=\"expand\",\n",
    "    ).set_index(0).T.iloc[0]\n",
    "\n",
    "min_idxs = better_idxmin(report_average_df).apply(join_with_and) \n",
    "max_idxs = better_idxmin(report_average_df).apply(join_with_and) \n",
    "max_nums = report_average_df.max().apply(lambda num: f\"{num:0.4f}\")\n",
    "min_nums = report_average_df.min().apply(lambda num: f\"{num:0.4f}\")"
   ]
  },
  {
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "display(Markdown(f\"\"\"\n",
    "\n",
    "Dari hasil pengujian, dapat dilihat bahwa dari rata-rata nilai *precision*, algoritma {max_idxs[\"Precision\"]} mendapat nilai tertinggi yaitu {max_nums[\"Precision\"]}, sedangkan {min_idxs[\"Precision\"]} terendah pada {min_nums[\"Precision\"]}. Untuk rata-rata nilai *recall*, {max_idxs[\"Recall\"]} mendapat nilai tertinggi dengan skor {max_nums[\"Recall\"]} sedangkan {min_idxs[\"Recall\"]} terendah dengan skor {min_nums[\"Recall\"]}. Untuk *F1-Score*, rata-rata nilai tertinggi terdapat pada algoritma {max_idxs[\"F1-Score\"]}, yaitu {max_nums[\"F1-Score\"]}, sementara rata-rata nilai terendah terdapat pada algoritma {min_idxs[\"F1-Score\"]} dengan nilai {min_nums[\"F1-Score\"]}. Pada rata-rata nilai *accuracy*, nilai tertinggi berada pada algoritma {max_idxs[\"Accuracy\"]} dengan nilai {max_nums[\"Accuracy\"]} dan nilai terendah berada pada algoritma {min_idxs[\"Accuracy\"]} dengan nilai {min_nums[\"Accuracy\"]}.\n",
    "\"\"\"\n",
    "))\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 286,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n\nDari hasil pengujian, dapat dilihat bahwa dari rata-rata nilai *precision*, algoritma *Support Vector Machine* mendapat nilai tertinggi yaitu 0.8213, sedangkan *Support Vector Machine* terendah pada 0.7885. Untuk rata-rata nilai *recall*, *Decision Tree* mendapat nilai tertinggi dengan skor 1.0000 sedangkan *Decision Tree* terendah dengan skor 0.8243. Untuk *F1-Score*, rata-rata nilai tertinggi terdapat pada algoritma *Decision Tree*, yaitu 0.8771, sementara rata-rata nilai terendah terdapat pada algoritma *Decision Tree* dengan nilai 0.8138. Pada rata-rata nilai *accuracy*, nilai tertinggi berada pada algoritma *Multilayer Perceptron* dengan nilai 0.7967 dan nilai terendah berada pada algoritma *Multilayer Perceptron* dengan nilai 0.7067.\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hoax-classification",
   "language": "python",
   "name": "hoax-classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}