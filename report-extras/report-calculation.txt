Untuk fold ke-1, algoritma Naive Bayes, jumlah true negative (tn) = 3, false positive (tp) = 9, false negative (fn) = 0; Dan true positive (tp) = 48. Maka nilai precision = tp / (tp + fp) =  48 / (48 + 9)= 0.8421052631578947; Nilai recall = tp / (tp + fn) = 48 / (48 + 0) = 1.0; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.8421052631578947 x 1.0 / (0.8421052631578947 + 1.0) = 0.9142857142857143; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 48 + 3 / (48 + 9 + 3 + 0) = 0.85.
Untuk fold ke-1, algoritma Support Vector Machine, jumlah true negative (tn) = 2, false positive (tp) = 10, false negative (fn) = 0; Dan true positive (tp) = 48. Maka nilai precision = tp / (tp + fp) =  48 / (48 + 10)= 0.8275862068965517; Nilai recall = tp / (tp + fn) = 48 / (48 + 0) = 1.0; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.8275862068965517 x 1.0 / (0.8275862068965517 + 1.0) = 0.9056603773584906; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 48 + 2 / (48 + 10 + 2 + 0) = 0.8333333333333334.
Untuk fold ke-1, algoritma Multilayer Perceptron, jumlah true negative (tn) = 9, false positive (tp) = 3, false negative (fn) = 8; Dan true positive (tp) = 40. Maka nilai precision = tp / (tp + fp) =  40 / (40 + 3)= 0.9302325581395349; Nilai recall = tp / (tp + fn) = 40 / (40 + 8) = 0.8333333333333334; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.9302325581395349 x 0.8333333333333334 / (0.9302325581395349 + 0.8333333333333334) = 0.8791208791208791; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 40 + 9 / (40 + 3 + 9 + 8) = 0.8166666666666667.
Untuk fold ke-1, algoritma Decision Tree, jumlah true negative (tn) = 7, false positive (tp) = 5, false negative (fn) = 4; Dan true positive (tp) = 44. Maka nilai precision = tp / (tp + fp) =  44 / (44 + 5)= 0.8979591836734694; Nilai recall = tp / (tp + fn) = 44 / (44 + 4) = 0.9166666666666666; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.8979591836734694 x 0.9166666666666666 / (0.8979591836734694 + 0.9166666666666666) = 0.9072164948453607; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 44 + 7 / (44 + 5 + 7 + 4) = 0.85.
Untuk fold ke-1, algoritma Random Forest, jumlah true negative (tn) = 6, false positive (tp) = 6, false negative (fn) = 2; Dan true positive (tp) = 46. Maka nilai precision = tp / (tp + fp) =  46 / (46 + 6)= 0.8846153846153846; Nilai recall = tp / (tp + fn) = 46 / (46 + 2) = 0.9583333333333334; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.8846153846153846 x 0.9583333333333334 / (0.8846153846153846 + 0.9583333333333334) = 0.9199999999999999; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 46 + 6 / (46 + 6 + 6 + 2) = 0.8666666666666667.
Untuk fold ke-2, algoritma Naive Bayes, jumlah true negative (tn) = 0, false positive (tp) = 1, false negative (fn) = 0; Dan true positive (tp) = 59. Maka nilai precision = tp / (tp + fp) =  59 / (59 + 1)= 0.9833333333333333; Nilai recall = tp / (tp + fn) = 59 / (59 + 0) = 1.0; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.9833333333333333 x 1.0 / (0.9833333333333333 + 1.0) = 0.9915966386554621; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 59 + 0 / (59 + 1 + 0 + 0) = 0.9833333333333333.
Untuk fold ke-2, algoritma Support Vector Machine, jumlah true negative (tn) = 0, false positive (tp) = 1, false negative (fn) = 0; Dan true positive (tp) = 59. Maka nilai precision = tp / (tp + fp) =  59 / (59 + 1)= 0.9833333333333333; Nilai recall = tp / (tp + fn) = 59 / (59 + 0) = 1.0; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.9833333333333333 x 1.0 / (0.9833333333333333 + 1.0) = 0.9915966386554621; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 59 + 0 / (59 + 1 + 0 + 0) = 0.9833333333333333.
Untuk fold ke-2, algoritma Multilayer Perceptron, jumlah true negative (tn) = 1, false positive (tp) = 0, false negative (fn) = 21; Dan true positive (tp) = 38. Maka nilai precision = tp / (tp + fp) =  38 / (38 + 0)= 1.0; Nilai recall = tp / (tp + fn) = 38 / (38 + 21) = 0.6440677966101694; F1-score = 2 x precision x recall / (precision + recall) = 2 x 1.0 x 0.6440677966101694 / (1.0 + 0.6440677966101694) = 0.7835051546391751; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 38 + 1 / (38 + 0 + 1 + 21) = 0.65.
Untuk fold ke-2, algoritma Decision Tree, jumlah true negative (tn) = 0, false positive (tp) = 1, false negative (fn) = 8; Dan true positive (tp) = 51. Maka nilai precision = tp / (tp + fp) =  51 / (51 + 1)= 0.9807692307692307; Nilai recall = tp / (tp + fn) = 51 / (51 + 8) = 0.864406779661017; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.9807692307692307 x 0.864406779661017 / (0.9807692307692307 + 0.864406779661017) = 0.918918918918919; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 51 + 0 / (51 + 1 + 0 + 8) = 0.85.
Untuk fold ke-2, algoritma Random Forest, jumlah true negative (tn) = 0, false positive (tp) = 1, false negative (fn) = 6; Dan true positive (tp) = 53. Maka nilai precision = tp / (tp + fp) =  53 / (53 + 1)= 0.9814814814814815; Nilai recall = tp / (tp + fn) = 53 / (53 + 6) = 0.8983050847457628; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.9814814814814815 x 0.8983050847457628 / (0.9814814814814815 + 0.8983050847457628) = 0.9380530973451328; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 53 + 0 / (53 + 1 + 0 + 6) = 0.8833333333333333.
Untuk fold ke-3, algoritma Naive Bayes, jumlah true negative (tn) = 0, false positive (tp) = 9, false negative (fn) = 0; Dan true positive (tp) = 51. Maka nilai precision = tp / (tp + fp) =  51 / (51 + 9)= 0.85; Nilai recall = tp / (tp + fn) = 51 / (51 + 0) = 1.0; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.85 x 1.0 / (0.85 + 1.0) = 0.9189189189189189; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 51 + 0 / (51 + 9 + 0 + 0) = 0.85.
Untuk fold ke-3, algoritma Support Vector Machine, jumlah true negative (tn) = 0, false positive (tp) = 9, false negative (fn) = 0; Dan true positive (tp) = 51. Maka nilai precision = tp / (tp + fp) =  51 / (51 + 9)= 0.85; Nilai recall = tp / (tp + fn) = 51 / (51 + 0) = 1.0; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.85 x 1.0 / (0.85 + 1.0) = 0.9189189189189189; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 51 + 0 / (51 + 9 + 0 + 0) = 0.85.
Untuk fold ke-3, algoritma Multilayer Perceptron, jumlah true negative (tn) = 0, false positive (tp) = 9, false negative (fn) = 6; Dan true positive (tp) = 45. Maka nilai precision = tp / (tp + fp) =  45 / (45 + 9)= 0.8333333333333334; Nilai recall = tp / (tp + fn) = 45 / (45 + 6) = 0.8823529411764706; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.8333333333333334 x 0.8823529411764706 / (0.8333333333333334 + 0.8823529411764706) = 0.8571428571428571; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 45 + 0 / (45 + 9 + 0 + 6) = 0.75.
Untuk fold ke-3, algoritma Decision Tree, jumlah true negative (tn) = 3, false positive (tp) = 6, false negative (fn) = 11; Dan true positive (tp) = 40. Maka nilai precision = tp / (tp + fp) =  40 / (40 + 6)= 0.8695652173913043; Nilai recall = tp / (tp + fn) = 40 / (40 + 11) = 0.7843137254901961; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.8695652173913043 x 0.7843137254901961 / (0.8695652173913043 + 0.7843137254901961) = 0.8247422680412372; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 40 + 3 / (40 + 6 + 3 + 11) = 0.7166666666666667.
Untuk fold ke-3, algoritma Random Forest, jumlah true negative (tn) = 3, false positive (tp) = 6, false negative (fn) = 7; Dan true positive (tp) = 44. Maka nilai precision = tp / (tp + fp) =  44 / (44 + 6)= 0.88; Nilai recall = tp / (tp + fn) = 44 / (44 + 7) = 0.8627450980392157; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.88 x 0.8627450980392157 / (0.88 + 0.8627450980392157) = 0.8712871287128714; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 44 + 3 / (44 + 6 + 3 + 7) = 0.7833333333333333.
Untuk fold ke-4, algoritma Naive Bayes, jumlah true negative (tn) = 2, false positive (tp) = 23, false negative (fn) = 0; Dan true positive (tp) = 35. Maka nilai precision = tp / (tp + fp) =  35 / (35 + 23)= 0.603448275862069; Nilai recall = tp / (tp + fn) = 35 / (35 + 0) = 1.0; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.603448275862069 x 1.0 / (0.603448275862069 + 1.0) = 0.7526881720430108; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 35 + 2 / (35 + 23 + 2 + 0) = 0.6166666666666667.
Untuk fold ke-4, algoritma Support Vector Machine, jumlah true negative (tn) = 2, false positive (tp) = 23, false negative (fn) = 0; Dan true positive (tp) = 35. Maka nilai precision = tp / (tp + fp) =  35 / (35 + 23)= 0.603448275862069; Nilai recall = tp / (tp + fn) = 35 / (35 + 0) = 1.0; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.603448275862069 x 1.0 / (0.603448275862069 + 1.0) = 0.7526881720430108; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 35 + 2 / (35 + 23 + 2 + 0) = 0.6166666666666667.
Untuk fold ke-4, algoritma Multilayer Perceptron, jumlah true negative (tn) = 6, false positive (tp) = 19, false negative (fn) = 1; Dan true positive (tp) = 34. Maka nilai precision = tp / (tp + fp) =  34 / (34 + 19)= 0.6415094339622641; Nilai recall = tp / (tp + fn) = 34 / (34 + 1) = 0.9714285714285714; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.6415094339622641 x 0.9714285714285714 / (0.6415094339622641 + 0.9714285714285714) = 0.7727272727272727; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 34 + 6 / (34 + 19 + 6 + 1) = 0.6666666666666666.
Untuk fold ke-4, algoritma Decision Tree, jumlah true negative (tn) = 8, false positive (tp) = 17, false negative (fn) = 3; Dan true positive (tp) = 32. Maka nilai precision = tp / (tp + fp) =  32 / (32 + 17)= 0.6530612244897959; Nilai recall = tp / (tp + fn) = 32 / (32 + 3) = 0.9142857142857143; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.6530612244897959 x 0.9142857142857143 / (0.6530612244897959 + 0.9142857142857143) = 0.7619047619047618; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 32 + 8 / (32 + 17 + 8 + 3) = 0.6666666666666666.
Untuk fold ke-4, algoritma Random Forest, jumlah true negative (tn) = 4, false positive (tp) = 21, false negative (fn) = 1; Dan true positive (tp) = 34. Maka nilai precision = tp / (tp + fp) =  34 / (34 + 21)= 0.6181818181818182; Nilai recall = tp / (tp + fn) = 34 / (34 + 1) = 0.9714285714285714; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.6181818181818182 x 0.9714285714285714 / (0.6181818181818182 + 0.9714285714285714) = 0.7555555555555554; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 34 + 4 / (34 + 21 + 4 + 1) = 0.6333333333333333.
Untuk fold ke-5, algoritma Naive Bayes, jumlah true negative (tn) = 1, false positive (tp) = 19, false negative (fn) = 0; Dan true positive (tp) = 40. Maka nilai precision = tp / (tp + fp) =  40 / (40 + 19)= 0.6779661016949152; Nilai recall = tp / (tp + fn) = 40 / (40 + 0) = 1.0; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.6779661016949152 x 1.0 / (0.6779661016949152 + 1.0) = 0.8080808080808081; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 40 + 1 / (40 + 19 + 1 + 0) = 0.6833333333333333.
Untuk fold ke-5, algoritma Support Vector Machine, jumlah true negative (tn) = 1, false positive (tp) = 19, false negative (fn) = 0; Dan true positive (tp) = 40. Maka nilai precision = tp / (tp + fp) =  40 / (40 + 19)= 0.6779661016949152; Nilai recall = tp / (tp + fn) = 40 / (40 + 0) = 1.0; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.6779661016949152 x 1.0 / (0.6779661016949152 + 1.0) = 0.8080808080808081; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 40 + 1 / (40 + 19 + 1 + 0) = 0.6833333333333333.
Untuk fold ke-5, algoritma Multilayer Perceptron, jumlah true negative (tn) = 2, false positive (tp) = 18, false negative (fn) = 3; Dan true positive (tp) = 37. Maka nilai precision = tp / (tp + fp) =  37 / (37 + 18)= 0.6727272727272727; Nilai recall = tp / (tp + fn) = 37 / (37 + 3) = 0.925; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.6727272727272727 x 0.925 / (0.6727272727272727 + 0.925) = 0.7789473684210527; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 37 + 2 / (37 + 18 + 2 + 3) = 0.65.
Untuk fold ke-5, algoritma Decision Tree, jumlah true negative (tn) = 4, false positive (tp) = 16, false negative (fn) = 7; Dan true positive (tp) = 33. Maka nilai precision = tp / (tp + fp) =  33 / (33 + 16)= 0.673469387755102; Nilai recall = tp / (tp + fn) = 33 / (33 + 7) = 0.825; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.673469387755102 x 0.825 / (0.673469387755102 + 0.825) = 0.7415730337078652; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 33 + 4 / (33 + 16 + 4 + 7) = 0.6166666666666667.
Untuk fold ke-5, algoritma Random Forest, jumlah true negative (tn) = 3, false positive (tp) = 17, false negative (fn) = 1; Dan true positive (tp) = 39. Maka nilai precision = tp / (tp + fp) =  39 / (39 + 17)= 0.6964285714285714; Nilai recall = tp / (tp + fn) = 39 / (39 + 1) = 0.975; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.6964285714285714 x 0.975 / (0.6964285714285714 + 0.975) = 0.8125; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 39 + 3 / (39 + 17 + 3 + 1) = 0.7.
