Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-1 pada algoritma Naive Bayes, jumlah true negative (tn) = 3.00, false positive (fp) = 9.00, false negative (fn) = 0.00; Dan true positive (tp) = 48.00. Maka nilai precision = tp / (tp + fp) =  48.00 / (48.00 + 9.00)= 0.84; Nilai recall = tp / (tp + fn) = 48.00 / (48.00 + 0.00) = 1.00; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.84 x 1.00 / (0.84 + 1.00) = 0.91; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 48.00 + 3.00 / (48.00 + 9.00 + 3.00 + 0.00) = 0.85.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-1 pada algoritma Support Vector Machine, jumlah true negative (tn) = 2.00, false positive (fp) = 10.00, false negative (fn) = 0.00; Dan true positive (tp) = 48.00. Maka nilai precision = tp / (tp + fp) =  48.00 / (48.00 + 10.00)= 0.83; Nilai recall = tp / (tp + fn) = 48.00 / (48.00 + 0.00) = 1.00; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.83 x 1.00 / (0.83 + 1.00) = 0.91; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 48.00 + 2.00 / (48.00 + 10.00 + 2.00 + 0.00) = 0.83.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-1 pada algoritma Multilayer Perceptron, jumlah true negative (tn) = 9.00, false positive (fp) = 3.00, false negative (fn) = 8.00; Dan true positive (tp) = 40.00. Maka nilai precision = tp / (tp + fp) =  40.00 / (40.00 + 3.00)= 0.93; Nilai recall = tp / (tp + fn) = 40.00 / (40.00 + 8.00) = 0.83; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.93 x 0.83 / (0.93 + 0.83) = 0.88; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 40.00 + 9.00 / (40.00 + 3.00 + 9.00 + 8.00) = 0.82.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-1 pada algoritma Decision Tree, jumlah true negative (tn) = 8.00, false positive (fp) = 4.00, false negative (fn) = 14.00; Dan true positive (tp) = 34.00. Maka nilai precision = tp / (tp + fp) =  34.00 / (34.00 + 4.00)= 0.89; Nilai recall = tp / (tp + fn) = 34.00 / (34.00 + 14.00) = 0.71; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.89 x 0.71 / (0.89 + 0.71) = 0.79; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 34.00 + 8.00 / (34.00 + 4.00 + 8.00 + 14.00) = 0.70.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-1 pada algoritma Random Forest, jumlah true negative (tn) = 5.00, false positive (fp) = 7.00, false negative (fn) = 4.00; Dan true positive (tp) = 44.00. Maka nilai precision = tp / (tp + fp) =  44.00 / (44.00 + 7.00)= 0.86; Nilai recall = tp / (tp + fn) = 44.00 / (44.00 + 4.00) = 0.92; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.86 x 0.92 / (0.86 + 0.92) = 0.89; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 44.00 + 5.00 / (44.00 + 7.00 + 5.00 + 4.00) = 0.82.
Berikut merupakan tabel hasil pengujian untuk fold 1.

Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-2 pada algoritma Naive Bayes, jumlah true negative (tn) = 0.00, false positive (fp) = 1.00, false negative (fn) = 0.00; Dan true positive (tp) = 59.00. Maka nilai precision = tp / (tp + fp) =  59.00 / (59.00 + 1.00)= 0.98; Nilai recall = tp / (tp + fn) = 59.00 / (59.00 + 0.00) = 1.00; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.98 x 1.00 / (0.98 + 1.00) = 0.99; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 59.00 + 0.00 / (59.00 + 1.00 + 0.00 + 0.00) = 0.98.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-2 pada algoritma Support Vector Machine, jumlah true negative (tn) = 0.00, false positive (fp) = 1.00, false negative (fn) = 0.00; Dan true positive (tp) = 59.00. Maka nilai precision = tp / (tp + fp) =  59.00 / (59.00 + 1.00)= 0.98; Nilai recall = tp / (tp + fn) = 59.00 / (59.00 + 0.00) = 1.00; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.98 x 1.00 / (0.98 + 1.00) = 0.99; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 59.00 + 0.00 / (59.00 + 1.00 + 0.00 + 0.00) = 0.98.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-2 pada algoritma Multilayer Perceptron, jumlah true negative (tn) = 1.00, false positive (fp) = 0.00, false negative (fn) = 21.00; Dan true positive (tp) = 38.00. Maka nilai precision = tp / (tp + fp) =  38.00 / (38.00 + 0.00)= 1.00; Nilai recall = tp / (tp + fn) = 38.00 / (38.00 + 21.00) = 0.64; F1-score = 2 x precision x recall / (precision + recall) = 2 x 1.00 x 0.64 / (1.00 + 0.64) = 0.78; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 38.00 + 1.00 / (38.00 + 0.00 + 1.00 + 21.00) = 0.65.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-2 pada algoritma Decision Tree, jumlah true negative (tn) = 0.00, false positive (fp) = 1.00, false negative (fn) = 8.00; Dan true positive (tp) = 51.00. Maka nilai precision = tp / (tp + fp) =  51.00 / (51.00 + 1.00)= 0.98; Nilai recall = tp / (tp + fn) = 51.00 / (51.00 + 8.00) = 0.86; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.98 x 0.86 / (0.98 + 0.86) = 0.92; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 51.00 + 0.00 / (51.00 + 1.00 + 0.00 + 8.00) = 0.85.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-2 pada algoritma Random Forest, jumlah true negative (tn) = 0.00, false positive (fp) = 1.00, false negative (fn) = 6.00; Dan true positive (tp) = 53.00. Maka nilai precision = tp / (tp + fp) =  53.00 / (53.00 + 1.00)= 0.98; Nilai recall = tp / (tp + fn) = 53.00 / (53.00 + 6.00) = 0.90; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.98 x 0.90 / (0.98 + 0.90) = 0.94; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 53.00 + 0.00 / (53.00 + 1.00 + 0.00 + 6.00) = 0.88.
Berikut merupakan tabel hasil pengujian untuk fold 2.

Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-3 pada algoritma Naive Bayes, jumlah true negative (tn) = 0.00, false positive (fp) = 9.00, false negative (fn) = 0.00; Dan true positive (tp) = 51.00. Maka nilai precision = tp / (tp + fp) =  51.00 / (51.00 + 9.00)= 0.85; Nilai recall = tp / (tp + fn) = 51.00 / (51.00 + 0.00) = 1.00; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.85 x 1.00 / (0.85 + 1.00) = 0.92; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 51.00 + 0.00 / (51.00 + 9.00 + 0.00 + 0.00) = 0.85.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-3 pada algoritma Support Vector Machine, jumlah true negative (tn) = 0.00, false positive (fp) = 9.00, false negative (fn) = 0.00; Dan true positive (tp) = 51.00. Maka nilai precision = tp / (tp + fp) =  51.00 / (51.00 + 9.00)= 0.85; Nilai recall = tp / (tp + fn) = 51.00 / (51.00 + 0.00) = 1.00; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.85 x 1.00 / (0.85 + 1.00) = 0.92; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 51.00 + 0.00 / (51.00 + 9.00 + 0.00 + 0.00) = 0.85.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-3 pada algoritma Multilayer Perceptron, jumlah true negative (tn) = 0.00, false positive (fp) = 9.00, false negative (fn) = 6.00; Dan true positive (tp) = 45.00. Maka nilai precision = tp / (tp + fp) =  45.00 / (45.00 + 9.00)= 0.83; Nilai recall = tp / (tp + fn) = 45.00 / (45.00 + 6.00) = 0.88; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.83 x 0.88 / (0.83 + 0.88) = 0.86; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 45.00 + 0.00 / (45.00 + 9.00 + 0.00 + 6.00) = 0.75.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-3 pada algoritma Decision Tree, jumlah true negative (tn) = 3.00, false positive (fp) = 6.00, false negative (fn) = 11.00; Dan true positive (tp) = 40.00. Maka nilai precision = tp / (tp + fp) =  40.00 / (40.00 + 6.00)= 0.87; Nilai recall = tp / (tp + fn) = 40.00 / (40.00 + 11.00) = 0.78; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.87 x 0.78 / (0.87 + 0.78) = 0.82; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 40.00 + 3.00 / (40.00 + 6.00 + 3.00 + 11.00) = 0.72.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-3 pada algoritma Random Forest, jumlah true negative (tn) = 4.00, false positive (fp) = 5.00, false negative (fn) = 5.00; Dan true positive (tp) = 46.00. Maka nilai precision = tp / (tp + fp) =  46.00 / (46.00 + 5.00)= 0.90; Nilai recall = tp / (tp + fn) = 46.00 / (46.00 + 5.00) = 0.90; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.90 x 0.90 / (0.90 + 0.90) = 0.90; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 46.00 + 4.00 / (46.00 + 5.00 + 4.00 + 5.00) = 0.83.
Berikut merupakan tabel hasil pengujian untuk fold 3.

Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-4 pada algoritma Naive Bayes, jumlah true negative (tn) = 2.00, false positive (fp) = 23.00, false negative (fn) = 0.00; Dan true positive (tp) = 35.00. Maka nilai precision = tp / (tp + fp) =  35.00 / (35.00 + 23.00)= 0.60; Nilai recall = tp / (tp + fn) = 35.00 / (35.00 + 0.00) = 1.00; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.60 x 1.00 / (0.60 + 1.00) = 0.75; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 35.00 + 2.00 / (35.00 + 23.00 + 2.00 + 0.00) = 0.62.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-4 pada algoritma Support Vector Machine, jumlah true negative (tn) = 2.00, false positive (fp) = 23.00, false negative (fn) = 0.00; Dan true positive (tp) = 35.00. Maka nilai precision = tp / (tp + fp) =  35.00 / (35.00 + 23.00)= 0.60; Nilai recall = tp / (tp + fn) = 35.00 / (35.00 + 0.00) = 1.00; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.60 x 1.00 / (0.60 + 1.00) = 0.75; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 35.00 + 2.00 / (35.00 + 23.00 + 2.00 + 0.00) = 0.62.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-4 pada algoritma Multilayer Perceptron, jumlah true negative (tn) = 6.00, false positive (fp) = 19.00, false negative (fn) = 1.00; Dan true positive (tp) = 34.00. Maka nilai precision = tp / (tp + fp) =  34.00 / (34.00 + 19.00)= 0.64; Nilai recall = tp / (tp + fn) = 34.00 / (34.00 + 1.00) = 0.97; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.64 x 0.97 / (0.64 + 0.97) = 0.77; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 34.00 + 6.00 / (34.00 + 19.00 + 6.00 + 1.00) = 0.67.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-4 pada algoritma Decision Tree, jumlah true negative (tn) = 8.00, false positive (fp) = 17.00, false negative (fn) = 3.00; Dan true positive (tp) = 32.00. Maka nilai precision = tp / (tp + fp) =  32.00 / (32.00 + 17.00)= 0.65; Nilai recall = tp / (tp + fn) = 32.00 / (32.00 + 3.00) = 0.91; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.65 x 0.91 / (0.65 + 0.91) = 0.76; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 32.00 + 8.00 / (32.00 + 17.00 + 8.00 + 3.00) = 0.67.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-4 pada algoritma Random Forest, jumlah true negative (tn) = 4.00, false positive (fp) = 21.00, false negative (fn) = 3.00; Dan true positive (tp) = 32.00. Maka nilai precision = tp / (tp + fp) =  32.00 / (32.00 + 21.00)= 0.60; Nilai recall = tp / (tp + fn) = 32.00 / (32.00 + 3.00) = 0.91; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.60 x 0.91 / (0.60 + 0.91) = 0.73; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 32.00 + 4.00 / (32.00 + 21.00 + 4.00 + 3.00) = 0.60.
Berikut merupakan tabel hasil pengujian untuk fold 4.

Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-5 pada algoritma Naive Bayes, jumlah true negative (tn) = 1.00, false positive (fp) = 19.00, false negative (fn) = 0.00; Dan true positive (tp) = 40.00. Maka nilai precision = tp / (tp + fp) =  40.00 / (40.00 + 19.00)= 0.68; Nilai recall = tp / (tp + fn) = 40.00 / (40.00 + 0.00) = 1.00; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.68 x 1.00 / (0.68 + 1.00) = 0.81; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 40.00 + 1.00 / (40.00 + 19.00 + 1.00 + 0.00) = 0.68.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-5 pada algoritma Support Vector Machine, jumlah true negative (tn) = 1.00, false positive (fp) = 19.00, false negative (fn) = 0.00; Dan true positive (tp) = 40.00. Maka nilai precision = tp / (tp + fp) =  40.00 / (40.00 + 19.00)= 0.68; Nilai recall = tp / (tp + fn) = 40.00 / (40.00 + 0.00) = 1.00; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.68 x 1.00 / (0.68 + 1.00) = 0.81; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 40.00 + 1.00 / (40.00 + 19.00 + 1.00 + 0.00) = 0.68.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-5 pada algoritma Multilayer Perceptron, jumlah true negative (tn) = 2.00, false positive (fp) = 18.00, false negative (fn) = 3.00; Dan true positive (tp) = 37.00. Maka nilai precision = tp / (tp + fp) =  37.00 / (37.00 + 18.00)= 0.67; Nilai recall = tp / (tp + fn) = 37.00 / (37.00 + 3.00) = 0.93; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.67 x 0.93 / (0.67 + 0.93) = 0.78; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 37.00 + 2.00 / (37.00 + 18.00 + 2.00 + 3.00) = 0.65.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-5 pada algoritma Decision Tree, jumlah true negative (tn) = 6.00, false positive (fp) = 14.00, false negative (fn) = 6.00; Dan true positive (tp) = 34.00. Maka nilai precision = tp / (tp + fp) =  34.00 / (34.00 + 14.00)= 0.71; Nilai recall = tp / (tp + fn) = 34.00 / (34.00 + 6.00) = 0.85; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.71 x 0.85 / (0.71 + 0.85) = 0.77; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 34.00 + 6.00 / (34.00 + 14.00 + 6.00 + 6.00) = 0.67.
Pada diagram dibawah, dapat dilihat bahwa untuk fold ke-5 pada algoritma Random Forest, jumlah true negative (tn) = 2.00, false positive (fp) = 18.00, false negative (fn) = 4.00; Dan true positive (tp) = 36.00. Maka nilai precision = tp / (tp + fp) =  36.00 / (36.00 + 18.00)= 0.67; Nilai recall = tp / (tp + fn) = 36.00 / (36.00 + 4.00) = 0.90; F1-score = 2 x precision x recall / (precision + recall) = 2 x 0.67 x 0.90 / (0.67 + 0.90) = 0.77; Nilai accuracy = tp + tn / (tp + fp + tn + fn) = 36.00 + 2.00 / (36.00 + 18.00 + 2.00 + 4.00) = 0.63.
Berikut merupakan tabel hasil pengujian untuk fold 5.

